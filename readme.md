# Learn random forests in R & databricks community

## Executive summary

Random forests are a machine learning approach that addesses the shortcomings
of decision trees. According to 2007 [research] random forests were in top-10
most popular machine learning algorithms. Random forests improve performance
by averaging multiple decision trees. The algorithm has **2** features that
help improve the performance.

**Bagging** is the first feature. Random forest generates a prediction based
on the average prediction of many decision trees. This approach works if the
trees are randomly different. 



Connect with me:

[<img align="left" alt="GeorgyMakarov | LinkedIn" width="22px" src="https://cdn.jsdelivr.net/npm/simple-icons@v3/icons/linkedin.svg"/>][Linkedin]  

<br />

Languages and tools used in this project:

[<img align="left" alt="GeorgyMakarov | Rstudio" width="22px" src="https://rstudio.com/wp-content/uploads/2018/10/RStudio-Logo-gray.svg"/>][Rstudio]  
[<img align="left" alt="GeorgyMakarov | Github" width="22px" src="https://cdn.jsdelivr.net/npm/simple-icons@v3/icons/github.svg"/>][Github]  
[<img align="left" alt="GeorgyMakarov | Git" width="22px" src="https://cdn.jsdelivr.net/npm/simple-icons@v3/icons/git.svg"/>][Git]  

<br />






<br />
<br />

[research]: https://dq-blog-files.s3.amazonaws.com/10Algorithms-08.pdf 
[Linkedin]: https://www.linkedin.com/in/georgy-makarov-11436b42/  
[Rstudio]: https://rstudio.com
[Github]: https://github.com  
[Git]: https://git-scm.com  


